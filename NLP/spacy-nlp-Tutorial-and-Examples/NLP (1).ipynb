{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e449a0cb-19e3-4f6c-8dba-c6650db4b1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\444\\anaconda3\\envs\\spacy_env\n",
      "\n",
      "  added / updated specs:\n",
      "    - python=3.11\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  bzip2              pkgs/main/win-64::bzip2-1.0.8-h2bbff1b_6 \n",
      "  ca-certificates    pkgs/main/win-64::ca-certificates-2025.2.25-haa95532_0 \n",
      "  libffi             pkgs/main/win-64::libffi-3.4.4-hd77b12b_1 \n",
      "  openssl            pkgs/main/win-64::openssl-3.0.16-h3f729d1_0 \n",
      "  pip                pkgs/main/noarch::pip-25.1-pyhc872135_2 \n",
      "  python             pkgs/main/win-64::python-3.11.11-h4607a30_0 \n",
      "  setuptools         pkgs/main/win-64::setuptools-78.1.1-py311haa95532_0 \n",
      "  sqlite             pkgs/main/win-64::sqlite-3.45.3-h2bbff1b_0 \n",
      "  tk                 pkgs/main/win-64::tk-8.6.14-h5e9d12e_1 \n",
      "  tzdata             pkgs/main/noarch::tzdata-2025b-h04d1e81_0 \n",
      "  vc                 pkgs/main/win-64::vc-14.42-haa95532_5 \n",
      "  vs2015_runtime     pkgs/main/win-64::vs2015_runtime-14.42.34433-hbfb602d_5 \n",
      "  wheel              pkgs/main/win-64::wheel-0.45.1-py311haa95532_0 \n",
      "  xz                 pkgs/main/win-64::xz-5.6.4-h4754444_1 \n",
      "  zlib               pkgs/main/win-64::zlib-1.2.13-h8cc25b3_1 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages: ...working... done\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate spacy_env\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda create -n spacy_env python=3.11 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "ea239cf9-3766-4d34-80a9-8704efd83a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed kernelspec spacy_env in C:\\Users\\444\\AppData\\Roaming\\jupyter\\kernels\\spacy_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "!python -m ipykernel install --user --name spacy_env --display-name \"Python (spacy_env)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "147f1490-acf9-4488-a0ea-07b99c9dacd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\444\\anaconda3\\lib\\site-packages (3.8.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\444\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\444\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\444\\anaconda3\\lib\\site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\444\\anaconda3\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\444\\anaconda3\\lib\\site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\444\\anaconda3\\lib\\site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\444\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\444\\anaconda3\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\444\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\444\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\444\\anaconda3\\lib\\site-packages (from spacy) (0.16.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\444\\anaconda3\\lib\\site-packages (from spacy) (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\444\\anaconda3\\lib\\site-packages (from spacy) (2.2.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\444\\anaconda3\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\444\\anaconda3\\lib\\site-packages (from spacy) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\444\\anaconda3\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\444\\anaconda3\\lib\\site-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\444\\anaconda3\\lib\\site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\444\\anaconda3\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\444\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\444\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\444\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\444\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\444\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\444\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\444\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\444\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\444\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\444\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\444\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\444\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\444\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\444\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\444\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\444\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\444\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\444\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\444\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\444\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\444\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "3baf362c-eb31-4d50-850e-48342bbd83f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/12.8 MB ? eta -:--:--\n",
      "     ------- -------------------------------- 2.4/12.8 MB 10.3 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 17.4 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 11.3/12.8 MB 18.0 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 16.7 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "7387973d-8b8a-4507-a5b6-b8e5a2249a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\444\\anaconda3\\lib\\site-packages (2.2.6)\n",
      "Collecting h5py\n",
      "  Downloading h5py-3.13.0-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting numpy>=1.19.3 (from h5py)\n",
      "  Downloading numpy-2.2.6-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Downloading h5py-3.13.0-cp312-cp312-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/3.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 12.3 MB/s eta 0:00:00\n",
      "Downloading numpy-2.2.6-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.4/12.6 MB 11.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.0/12.6 MB 24.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 22.6 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy, h5py\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.13.0\n",
      "    Uninstalling h5py-3.13.0:\n",
      "      Successfully uninstalled h5py-3.13.0\n",
      "Successfully installed h5py-3.13.0 numpy-2.2.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\444\\anaconda3\\Lib\\site-packages\\~-mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\444\\anaconda3\\Lib\\site-packages\\~~mpy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\444\\anaconda3\\Lib\\site-packages\\~-py'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.2.6 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numpy\n",
    "!pip install --force-reinstall --no-cache-dir h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "3703ccac-b937-47bd-bfc3-59db3b503e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "89f8a289-cb35-4ecb-8e02-97ff9da7c29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '| Loading compatibility table...',\n",
       " '/ Loading compatibility table...',\n",
       " '\\x1b[2K\\x1b[38;5;2m[+] Loaded compatibility table\\x1b[0m',\n",
       " '\\x1b[1m',\n",
       " '================= Installed pipeline packages (spaCy v3.8.7) =================\\x1b[0m',\n",
       " '\\x1b[38;5;4m[i] spaCy installation:',\n",
       " 'C:\\\\Users\\\\444\\\\anaconda3\\\\Lib\\\\site-packages\\\\spacy\\x1b[0m',\n",
       " '',\n",
       " 'NAME             SPACY            VERSION                              ',\n",
       " 'en_core_web_sm   >=3.8.0,<3.9.0   \\x1b[38;5;2m3.8.0\\x1b[0m   \\x1b[38;5;2m[+]\\x1b[0m',\n",
       " '']"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!python -m spacy validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bc84561-7210-4368-ba1f-d2026e777437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31463866-1ea1-4573-898a-b349af4754a6",
   "metadata": {},
   "source": [
    "# 1. Named Entities Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f0f09e3-b3e3-4b60-b3ef-dceecc999912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taylor Swift , PERSON\n",
      "Los Angeles , GPE\n",
      "March 3rd, 2023 , DATE\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Taylor Swift performed in Los Angeles on March 3rd, 2023.\")\n",
    "\n",
    "for entity in doc.ents:\n",
    "    print(entity,\",\", entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc05e9fb-31e6-4205-ba1b-8e7aefc5c4ed",
   "metadata": {},
   "source": [
    "# 2. Entity Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d547927c-812a-41cc-aa41-23580b8050a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serena Williams\n",
      "Tom Hanks\n"
     ]
    }
   ],
   "source": [
    "def ent_in_sentance(sentance):\n",
    "    doc = nlp(sentance)\n",
    "    for entity in doc.ents:\n",
    "        if entity.label_ == \"PERSON\":\n",
    "            print(entity)\n",
    "\n",
    "ent_in_sentance(\"Serena Williams had dinner with Tom Hanks in Paris.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9690bf1d-93b8-4f40-a634-7092b18d43bf",
   "metadata": {},
   "source": [
    "# 3. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e9cfd89-2305-4d66-8e74-b2294ac63944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She  ---->  she\n",
      "was  ---->  be\n",
      "running  ---->  run\n",
      "and  ---->  and\n",
      "had  ---->  have\n",
      "run  ---->  run\n",
      "5  ---->  5\n",
      "kilometers  ---->  kilometer\n",
      "by  ---->  by\n",
      "7  ---->  7\n",
      "am  ---->  am\n",
      ".  ---->  .\n"
     ]
    }
   ],
   "source": [
    "def lemma_in_sentance(sentance):\n",
    "    doc = nlp(sentance)\n",
    "    for token in doc:\n",
    "        print(token.text, \" ----> \", token.lemma_)\n",
    "\n",
    "\n",
    "lemma_in_sentance(\"She was running and had run 5 kilometers by 7am.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fb3ba7-8838-4dc0-aecd-b7aad60d98e0",
   "metadata": {},
   "source": [
    "# 4. Stop Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4758d850-98c9-41f0-b053-dc3987902d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['example', 'sentence', 'stop', 'words']\n"
     ]
    }
   ],
   "source": [
    "def print_not_stop_words(sentance):\n",
    "    doc = nlp(sentance)\n",
    "    not_stop_words = []\n",
    "    for token in doc:\n",
    "        if not token.is_stop and not token.is_punct:\n",
    "            not_stop_words.append(token.text)\n",
    "    print(not_stop_words)\n",
    "\n",
    "print_not_stop_words(\"This is an example sentence with some stop words.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7659f4e2-4e76-4549-b507-4e56c9386234",
   "metadata": {},
   "source": [
    "# 5. Custom Stop Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9625a89-917b-4040-af76-194dd1da4f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is\n",
      "and\n",
      "powerful\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"SpaCy is awesome and powerful.\")\n",
    "nlp.vocab[\"powerful\"].is_stop = True\n",
    "\n",
    "for token in doc:\n",
    "    if token.is_stop:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b57db46-606a-44d0-9393-faf410641390",
   "metadata": {},
   "source": [
    "# 6. Phrase Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0aaee6bc-197c-40b4-b5fd-dcb4a35a028f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence\n",
      "artificial intelligence\n",
      "AI\n",
      "artificial-intelligence\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "\n",
    "patterns = [nlp(\"artificial intelligence\"),\n",
    "            nlp(\"Artificial Intelligence\"),\n",
    "            nlp(\"artificial-intelligence\"),\n",
    "            nlp(\"Artificial-Intelligence\"),\n",
    "            nlp(\"AI\")]\n",
    "\n",
    "matcher.add(\"artificial intelligence\", patterns)\n",
    "\n",
    "doc = nlp(\"Artificial Intelligence is the future. I study artificial intelligence. Sometimes, when I think of AI i wonder how artificial-intelligence will change the world we live in.\")\n",
    "matches = matcher(doc)\n",
    "\n",
    "for match_id, start, end in matches:\n",
    "    print(doc[start:end].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da1ef5a-5a9b-4299-9d44-c3c5c26765cf",
   "metadata": {},
   "source": [
    "# 7. POS Tagging + Explanation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53c0512f-baeb-492c-89a4-9f03f9438547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ,  DET ,  determiner\n",
      "cat ,  NOUN ,  noun\n",
      "sat ,  VERB ,  verb\n",
      "on ,  ADP ,  adposition\n",
      "the ,  DET ,  determiner\n",
      "mat ,  NOUN ,  noun\n",
      ". ,  PUNCT ,  punctuation\n"
     ]
    }
   ],
   "source": [
    "from spacy import explain\n",
    "\n",
    "doc = nlp(\"The cat sat on the mat.\")\n",
    "for token in doc:\n",
    "    print(token.text,\", \", token.pos_,\", \", spacy.explain(token.pos_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c074418-5a44-44a5-aeea-19e4c0d28c6b",
   "metadata": {},
   "source": [
    "# 8. Accessing the Pipeline + Custom Sentence Separator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51dd4636-9739-4685-b76a-14563ceb8e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaCy is great\n",
      "It helps with NLP tasks\n",
      "Really useful.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "\n",
    "if \"parser\" in nlp.pipe_names:\n",
    "    nlp.remove_pipe(\"parser\")\n",
    "    \n",
    "if \"sentencizer\" not in nlp.pipe_names:\n",
    "    nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "@Language.component('set_custom_boundaries')\n",
    "def set_custom_boundaries(doc):\n",
    "    for i, token in enumerate(doc[:-1]):\n",
    "        if token.text == '^':\n",
    "            token.is_sent_start = False\n",
    "            doc[i+1].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "# מוסיפים את השלב אחרי sentencizer – כדי לשנות את הסימנים\n",
    "if \"set_custom_boundaries\" not in nlp.pipe_names:\n",
    "    nlp.add_pipe(\"set_custom_boundaries\", after=\"sentencizer\")\n",
    "\n",
    "# בדיקה\n",
    "doc = nlp('SpaCy is great ^ It helps with NLP tasks ^ Really useful.')\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print(sent.text.replace(\"^\", \"\").strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b126a4-a9f5-49bf-baae-b1a88a304d92",
   "metadata": {},
   "source": [
    "# 9. POS Tagging + Displacy Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afcee4e6-b428-4647-9b42-09b38868104a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence:  Sometimes I feel lost within this crazy world of AI! Help!!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sometimes    ADV    adverb\n",
      "I    PRON    pronoun\n",
      "feel    VERB    verb\n",
      "lost    VERB    verb\n",
      "within    ADP    adposition\n",
      "this    DET    determiner\n",
      "crazy    ADJ    adjective\n",
      "world    NOUN    noun\n",
      "of    ADP    adposition\n",
      "AI    PROPN    proper noun\n",
      "!    PUNCT    punctuation\n",
      "Help    VERB    verb\n",
      "!    PUNCT    punctuation\n",
      "!    PUNCT    punctuation\n",
      "!    PUNCT    punctuation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\444\\anaconda3\\Lib\\site-packages\\spacy\\displacy\\__init__.py:141: UserWarning: [W005] Doc object not parsed. This means displaCy won't be able to generate a dependency visualization for it. Make sure the Doc was processed with a model that supports dependency parsing, and not just a language class like `English()`. For more info, see the docs:\n",
      "https://spacy.io/usage/models\n",
      "  warnings.warn(Warnings.W005)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"f10d3f568bba432dac2b45df0242c81c-0\" class=\"displacy\" width=\"1975\" height=\"137.0\" direction=\"ltr\" style=\"max-width: none; height: 137.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Sometimes</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">feel</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">lost</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">within</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">this</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">crazy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">world</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">AI!</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">Help!!!</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">VERB</tspan>\n",
       "</text>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "sentence = input(\"Enter a sentence: \")\n",
    "doc = nlp(sentence)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text,\"  \", token.pos_,\"  \", spacy.explain(token.pos_))\n",
    "\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a152e068-b65b-45bf-b361-1463d137cf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "35605f2f-bc62-44ef-8bbe-52505219399a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love you mom, you are so great it meakes my heart explode and my eyes want to pop out! wow!! \n",
      "\n",
      "I\n",
      "\n",
      "token.text -  I\n",
      "token.ent_type_ - Not entity\n",
      "token.ent_iob_ -  O\n",
      "token.pos_ -  PRON\n",
      "spacy.explain(token.pos_) -  pronoun\n",
      "token.dep_ -  nsubj\n",
      "spacy.explain(token.dep_) -  nominal subject\n",
      "token.is_stop  -  True\n",
      "token.is_punct -  False\n",
      "token.like_num -  False\n",
      "token.is_sent_start -  True\n",
      "token.lemma_ -  I\n",
      "token.tag_ -  PRP\n",
      "token.is_alpha -  True\n",
      "token.morph -  Case=Nom|Number=Sing|Person=1|PronType=Prs\n",
      "token.idx -  0\n",
      "\n",
      "\n",
      "love\n",
      "\n",
      "token.text -  love\n",
      "token.ent_type_ - Not entity\n",
      "token.ent_iob_ -  O\n",
      "token.pos_ -  VERB\n",
      "spacy.explain(token.pos_) -  verb\n",
      "token.dep_ -  ccomp\n",
      "spacy.explain(token.dep_) -  clausal complement\n",
      "token.is_stop  -  False\n",
      "token.is_punct -  False\n",
      "token.like_num -  False\n",
      "token.is_sent_start -  False\n",
      "token.lemma_ -  love\n",
      "token.tag_ -  VBP\n",
      "token.is_alpha -  True\n",
      "token.morph -  Tense=Pres|VerbForm=Fin\n",
      "token.idx -  2\n",
      "\n",
      "\n",
      "you\n",
      "\n",
      "token.text -  you\n",
      "token.ent_type_ - Not entity\n",
      "token.ent_iob_ -  O\n",
      "token.pos_ -  PRON\n",
      "spacy.explain(token.pos_) -  pronoun\n",
      "token.dep_ -  dobj\n",
      "spacy.explain(token.dep_) -  direct object\n",
      "token.is_stop  -  True\n",
      "token.is_punct -  False\n",
      "token.like_num -  False\n",
      "token.is_sent_start -  False\n",
      "token.lemma_ -  you\n",
      "token.tag_ -  PRP\n",
      "token.is_alpha -  True\n",
      "token.morph -  Case=Acc|Person=2|PronType=Prs\n",
      "token.idx -  7\n",
      "\n",
      "\n",
      "mom\n",
      "\n",
      "token.text -  mom\n",
      "token.ent_type_ - Not entity\n",
      "token.ent_iob_ -  O\n",
      "token.pos_ -  NOUN\n",
      "spacy.explain(token.pos_) -  noun\n",
      "token.dep_ -  npadvmod\n",
      "spacy.explain(token.dep_) -  noun phrase as adverbial modifier\n",
      "token.is_stop  -  False\n",
      "token.is_punct -  False\n",
      "token.like_num -  False\n",
      "token.is_sent_start -  False\n",
      "token.lemma_ -  mom\n",
      "token.tag_ -  NN\n",
      "token.is_alpha -  True\n",
      "token.morph -  Number=Sing\n",
      "token.idx -  11\n",
      "\n",
      "\n",
      ",\n",
      "\n",
      "token.text -  ,\n",
      "token.ent_type_ - Not entity\n",
      "token.ent_iob_ -  O\n",
      "token.pos_ -  PUNCT\n",
      "spacy.explain(token.pos_) -  punctuation\n",
      "token.dep_ -  punct\n",
      "spacy.explain(token.dep_) -  punctuation\n",
      "token.is_stop  -  False\n",
      "token.is_punct -  True\n",
      "token.like_num -  False\n",
      "token.is_sent_start -  False\n",
      "token.lemma_ -  ,\n",
      "token.tag_ -  ,\n",
      "token.is_alpha -  False\n",
      "token.morph -  PunctType=Comm\n",
      "token.idx -  14\n",
      "\n",
      "\n",
      "you\n",
      "\n",
      "token.text -  you\n",
      "token.ent_type_ - Not entity\n",
      "token.ent_iob_ -  O\n",
      "token.pos_ -  PRON\n",
      "spacy.explain(token.pos_) -  pronoun\n",
      "token.dep_ -  nsubj\n",
      "spacy.explain(token.dep_) -  nominal subject\n",
      "token.is_stop  -  True\n",
      "token.is_punct -  False\n",
      "token.like_num -  False\n",
      "token.is_sent_start -  False\n",
      "token.lemma_ -  you\n",
      "token.tag_ -  PRP\n",
      "token.is_alpha -  True\n",
      "token.morph -  Case=Nom|Person=2|PronType=Prs\n",
      "token.idx -  16\n",
      "\n",
      "\n",
      "are\n",
      "\n",
      "token.text -  are\n",
      "token.ent_type_ - Not entity\n",
      "token.ent_iob_ -  O\n",
      "token.pos_ -  AUX\n",
      "spacy.explain(token.pos_) -  auxiliary\n",
      "token.dep_ -  ROOT\n",
      "spacy.explain(token.dep_) -  root\n",
      "token.is_stop  -  True\n",
      "token.is_punct -  False\n",
      "token.like_num -  False\n",
      "token.is_sent_start -  False\n",
      "token.lemma_ -  be\n",
      "token.tag_ -  VBP\n",
      "token.is_alpha -  True\n",
      "token.morph -  Mood=Ind|Tense=Pres|VerbForm=Fin\n",
      "token.idx -  20\n",
      "\n",
      "\n",
      "so\n",
      "\n",
      "token.text -  so\n",
      "token.ent_type_ - Not entity\n",
      "token.ent_iob_ -  O\n",
      "token.pos_ -  ADV\n",
      "spacy.explain(token.pos_) -  adverb\n",
      "token.dep_ -  advmod\n",
      "spacy.explain(token.dep_) -  adverbial modifier\n",
      "token.is_stop  -  True\n",
      "token.is_punct -  False\n",
      "token.like_num -  False\n",
      "token.is_sent_start -  False\n",
      "token.lemma_ -  so\n",
      "token.tag_ -  RB\n",
      "token.is_alpha -  True\n",
      "token.morph -  \n",
      "token.idx -  24\n",
      "\n",
      "\n",
      "great\n",
      "\n",
      "token.text -  great\n",
      "token.ent_type_ - Not entity\n",
      "token.ent_iob_ -  O\n",
      "token.pos_ -  ADJ\n",
      "spacy.explain(token.pos_) -  adjective\n",
      "token.dep_ -  acomp\n",
      "spacy.explain(token.dep_) -  adjectival complement\n",
      "token.is_stop  -  False\n",
      "token.is_punct -  False\n",
      "token.like_num -  False\n",
      "token.is_sent_start -  False\n",
      "token.lemma_ -  great\n",
      "token.tag_ -  JJ\n",
      "token.is_alpha -  True\n",
      "token.morph -  Degree=Pos\n",
      "token.idx -  27\n",
      "\n",
      "\n",
      "it\n",
      "\n",
      "token.text -  it\n",
      "token.ent_type_ - Not entity\n",
      "token.ent_iob_ -  O\n",
      "token.pos_ -  PRON\n",
      "spacy.explain(token.pos_) -  pronoun\n",
      "token.dep_ -  nsubj\n",
      "spacy.explain(token.dep_) -  nominal subject\n",
      "token.is_stop  -  True\n",
      "token.is_punct -  False\n",
      "token.like_num -  False\n",
      "token.is_sent_start -  False\n",
      "token.lemma_ -  it\n",
      "token.tag_ -  PRP\n",
      "token.is_alpha -  True\n",
      "token.morph -  Case=Nom|Gender=Neut|Number=Sing|Person=3|PronType=Prs\n",
      "token.idx -  33\n",
      "\n",
      "\n",
      "meakes\n",
      "\n",
      "token.text -  meakes\n",
      "token.ent_type_ - Not entity\n",
      "token.ent_iob_ -  O\n",
      "token.pos_ -  VERB\n",
      "spacy.explain(token.pos_) -  verb\n",
      "token.dep_ -  ccomp\n",
      "spacy.explain(token.dep_) -  clausal complement\n",
      "token.is_stop  -  False\n",
      "token.is_punct -  False\n",
      "token.like_num -  False\n",
      "token.is_sent_start -  False\n",
      "token.lemma_ -  meake\n",
      "token.tag_ -  VBZ\n",
      "token.is_alpha -  True\n",
      "token.morph -  Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "token.idx -  36\n",
      "\n",
      "\n",
      "my\n",
      "\n",
      "token.text -  my\n",
      "token.ent_type_ - Not entity\n",
      "token.ent_iob_ -  O\n",
      "token.pos_ -  PRON\n",
      "spacy.explain(token.pos_) -  pronoun\n",
      "token.dep_ -  poss\n",
      "spacy.explain(token.dep_) -  possession modifier\n",
      "token.is_stop  -  True\n",
      "token.is_punct -  False\n",
      "token.like_num -  False\n",
      "token.is_sent_start -  False\n",
      "token.lemma_ -  my\n",
      "token.tag_ -  PRP$\n",
      "token.is_alpha -  True\n",
      "token.morph -  Number=Sing|Person=1|Poss=Yes|PronType=Prs\n",
      "token.idx -  43\n",
      "\n",
      "\n",
      "heart\n",
      "\n",
      "token.text -  heart\n",
      "token.ent_type_ - Not entity\n",
      "token.ent_iob_ -  O\n",
      "token.pos_ -  NOUN\n",
      "spacy.explain(token.pos_) -  noun\n",
      "token.dep_ -  nsubj\n",
      "spacy.explain(token.dep_) -  nominal subject\n",
      "token.is_stop  -  False\n",
      "token.is_punct -  False\n",
      "token.like_num -  False\n",
      "token.is_sent_start -  False\n",
      "token.lemma_ -  heart\n",
      "token.tag_ -  NN\n",
      "token.is_alpha -  True\n",
      "token.morph -  Number=Sing\n",
      "token.idx -  46\n",
      "\n",
      "\n",
      "explode\n",
      "\n",
      "token.text -  explode\n",
      "token.ent_type_ - Not entity\n",
      "token.ent_iob_ -  O\n",
      "token.pos_ -  VERB\n",
      "spacy.explain(token.pos_) -  verb\n",
      "token.dep_ -  ccomp\n",
      "spacy.explain(token.dep_) -  clausal complement\n",
      "token.is_stop  -  False\n",
      "token.is_punct -  False\n",
      "token.like_num -  False\n",
      "token.is_sent_start -  False\n",
      "token.lemma_ -  explode\n",
      "token.tag_ -  VB\n",
      "token.is_alpha -  True\n",
      "token.morph -  VerbForm=Inf\n",
      "token.idx -  52\n",
      "\n",
      "\n",
      "and\n",
      "\n",
      "token.text -  and\n",
      "token.ent_type_ - Not entity\n",
      "token.ent_iob_ -  O\n",
      "token.pos_ -  CCONJ\n",
      "spacy.explain(token.pos_) -  coordinating conjunction\n",
      "token.dep_ -  cc\n",
      "spacy.explain(token.dep_) -  coordinating conjunction\n",
      "token.is_stop  -  True\n",
      "token.is_punct -  False\n",
      "token.like_num -  False\n",
      "token.is_sent_start -  False\n",
      "token.lemma_ -  and\n",
      "token.tag_ -  CC\n",
      "token.is_alpha -  True\n",
      "token.morph -  ConjType=Cmp\n",
      "token.idx -  60\n",
      "\n",
      "\n",
      "my\n",
      "\n",
      "token.text -  my\n",
      "token.ent_type_ - Not entity\n",
      "token.ent_iob_ -  O\n",
      "token.pos_ -  PRON\n",
      "spacy.explain(token.pos_) -  pronoun\n",
      "token.dep_ -  poss\n",
      "spacy.explain(token.dep_) -  possession modifier\n",
      "token.is_stop  -  True\n",
      "token.is_punct -  False\n",
      "token.like_num -  False\n",
      "token.is_sent_start -  False\n",
      "token.lemma_ -  my\n",
      "token.tag_ -  PRP$\n",
      "token.is_alpha -  True\n",
      "token.morph -  Number=Sing|Person=1|Poss=Yes|PronType=Prs\n",
      "token.idx -  64\n",
      "\n",
      "\n",
      "eyes\n",
      "\n",
      "token.text -  eyes\n",
      "token.ent_type_ - Not entity\n",
      "token.ent_iob_ -  O\n",
      "token.pos_ -  NOUN\n",
      "spacy.explain(token.pos_) -  noun\n",
      "token.dep_ -  nsubj\n",
      "spacy.explain(token.dep_) -  nominal subject\n",
      "token.is_stop  -  False\n",
      "token.is_punct -  False\n",
      "token.like_num -  False\n",
      "token.is_sent_start -  False\n",
      "token.lemma_ -  eye\n",
      "token.tag_ -  NNS\n",
      "token.is_alpha -  True\n",
      "token.morph -  Number=Plur\n",
      "token.idx -  67\n",
      "\n",
      "\n",
      "want\n",
      "\n",
      "token.text -  want\n",
      "token.ent_type_ - Not entity\n",
      "token.ent_iob_ -  O\n",
      "token.pos_ -  VERB\n",
      "spacy.explain(token.pos_) -  verb\n",
      "token.dep_ -  conj\n",
      "spacy.explain(token.dep_) -  conjunct\n",
      "token.is_stop  -  False\n",
      "token.is_punct -  False\n",
      "token.like_num -  False\n",
      "token.is_sent_start -  False\n",
      "token.lemma_ -  want\n",
      "token.tag_ -  VBP\n",
      "token.is_alpha -  True\n",
      "token.morph -  Tense=Pres|VerbForm=Fin\n",
      "token.idx -  72\n",
      "\n",
      "\n",
      "to\n",
      "\n",
      "token.text -  to\n",
      "token.ent_type_ - Not entity\n",
      "token.ent_iob_ -  O\n",
      "token.pos_ -  PART\n",
      "spacy.explain(token.pos_) -  particle\n",
      "token.dep_ -  aux\n",
      "spacy.explain(token.dep_) -  auxiliary\n",
      "token.is_stop  -  True\n",
      "token.is_punct -  False\n",
      "token.like_num -  False\n",
      "token.is_sent_start -  False\n",
      "token.lemma_ -  to\n",
      "token.tag_ -  TO\n",
      "token.is_alpha -  True\n",
      "token.morph -  \n",
      "token.idx -  77\n",
      "\n",
      "\n",
      "pop\n",
      "\n",
      "token.text -  pop\n",
      "token.ent_type_ - Not entity\n",
      "token.ent_iob_ -  O\n",
      "token.pos_ -  VERB\n",
      "spacy.explain(token.pos_) -  verb\n",
      "token.dep_ -  xcomp\n",
      "spacy.explain(token.dep_) -  open clausal complement\n",
      "token.is_stop  -  False\n",
      "token.is_punct -  False\n",
      "token.like_num -  False\n",
      "token.is_sent_start -  False\n",
      "token.lemma_ -  pop\n",
      "token.tag_ -  VB\n",
      "token.is_alpha -  True\n",
      "token.morph -  VerbForm=Inf\n",
      "token.idx -  80\n",
      "\n",
      "\n",
      "out\n",
      "\n",
      "token.text -  out\n",
      "token.ent_type_ - Not entity\n",
      "token.ent_iob_ -  O\n",
      "token.pos_ -  ADP\n",
      "spacy.explain(token.pos_) -  adposition\n",
      "token.dep_ -  prt\n",
      "spacy.explain(token.dep_) -  particle\n",
      "token.is_stop  -  True\n",
      "token.is_punct -  False\n",
      "token.like_num -  False\n",
      "token.is_sent_start -  False\n",
      "token.lemma_ -  out\n",
      "token.tag_ -  RP\n",
      "token.is_alpha -  True\n",
      "token.morph -  \n",
      "token.idx -  84\n",
      "\n",
      "\n",
      "!\n",
      "\n",
      "token.text -  !\n",
      "token.ent_type_ - Not entity\n",
      "token.ent_iob_ -  O\n",
      "token.pos_ -  PUNCT\n",
      "spacy.explain(token.pos_) -  punctuation\n",
      "token.dep_ -  punct\n",
      "spacy.explain(token.dep_) -  punctuation\n",
      "token.is_stop  -  False\n",
      "token.is_punct -  True\n",
      "token.like_num -  False\n",
      "token.is_sent_start -  False\n",
      "token.lemma_ -  !\n",
      "token.tag_ -  .\n",
      "token.is_alpha -  False\n",
      "token.morph -  PunctType=Peri\n",
      "token.idx -  87\n",
      "\n",
      "\n",
      "wow\n",
      "\n",
      "token.text -  wow\n",
      "token.ent_type_ - Not entity\n",
      "token.ent_iob_ -  O\n",
      "token.pos_ -  INTJ\n",
      "spacy.explain(token.pos_) -  interjection\n",
      "token.dep_ -  ROOT\n",
      "spacy.explain(token.dep_) -  root\n",
      "token.is_stop  -  False\n",
      "token.is_punct -  False\n",
      "token.like_num -  False\n",
      "token.is_sent_start -  True\n",
      "token.lemma_ -  wow\n",
      "token.tag_ -  UH\n",
      "token.is_alpha -  True\n",
      "token.morph -  \n",
      "token.idx -  89\n",
      "\n",
      "\n",
      "!\n",
      "\n",
      "token.text -  !\n",
      "token.ent_type_ - Not entity\n",
      "token.ent_iob_ -  O\n",
      "token.pos_ -  PUNCT\n",
      "spacy.explain(token.pos_) -  punctuation\n",
      "token.dep_ -  punct\n",
      "spacy.explain(token.dep_) -  punctuation\n",
      "token.is_stop  -  False\n",
      "token.is_punct -  True\n",
      "token.like_num -  False\n",
      "token.is_sent_start -  False\n",
      "token.lemma_ -  !\n",
      "token.tag_ -  .\n",
      "token.is_alpha -  False\n",
      "token.morph -  PunctType=Peri\n",
      "token.idx -  92\n",
      "\n",
      "\n",
      "!\n",
      "\n",
      "token.text -  !\n",
      "token.ent_type_ - Not entity\n",
      "token.ent_iob_ -  O\n",
      "token.pos_ -  PUNCT\n",
      "spacy.explain(token.pos_) -  punctuation\n",
      "token.dep_ -  punct\n",
      "spacy.explain(token.dep_) -  punctuation\n",
      "token.is_stop  -  False\n",
      "token.is_punct -  True\n",
      "token.like_num -  False\n",
      "token.is_sent_start -  False\n",
      "token.lemma_ -  !\n",
      "token.tag_ -  .\n",
      "token.is_alpha -  False\n",
      "token.morph -  PunctType=Peri\n",
      "token.idx -  93\n",
      "\n",
      "\n",
      "===== Named Entities (doc.ents) =====\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('I love you mom, you are so great it meakes my heart explode and my eyes want to pop out! wow!! ')\n",
    "print (doc.text)\n",
    "print()\n",
    "\n",
    "for token in doc:\n",
    "    print(token)\n",
    "    print()\n",
    "    print(\"token.text - \", token.text)\n",
    "    print(\"token.ent_type_ -\", token.ent_type_ if token.ent_type_ else \"Not entity\")\n",
    "    print(\"token.ent_iob_ - \", token.ent_iob_)\n",
    "    print(\"token.pos_ - \", token.pos_)\n",
    "    print(\"spacy.explain(token.pos_) - \", spacy.explain(token.pos_))\n",
    "    print(\"token.dep_ - \", token.dep_)\n",
    "    print(\"spacy.explain(token.dep_) - \", spacy.explain(token.dep_))\n",
    "    print(\"token.is_stop  - \", token.is_stop )\n",
    "    print(\"token.is_punct - \", token.is_punct)\n",
    "    print(\"token.like_num - \", token.like_num)\n",
    "    print(\"token.is_sent_start - \", token.is_sent_start)\n",
    "    print(\"token.lemma_ - \", token.lemma_)\n",
    "    print(\"token.tag_ - \", token.tag_)\n",
    "    print(\"token.is_alpha - \", token.is_alpha)\n",
    "    print(\"token.morph - \", token.morph)\n",
    "    print(\"token.idx - \", token.idx)\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "print(\"===== Named Entities (doc.ents) =====\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text:<25} {ent.label_:<10} {spacy.explain(ent.label_)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836a0ada-87fb-4051-9d79-39fda53bfaac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spacy_env)",
   "language": "python",
   "name": "spacy_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
